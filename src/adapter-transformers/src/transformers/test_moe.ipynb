{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsely-Gated Mixture-of-Experts Layers.\n",
    "# See \"Outrageously Large Neural Networks\"\n",
    "# https://arxiv.org/abs/1701.06538\n",
    "#\n",
    "# Author: David Rau\n",
    "#\n",
    "# The code is based on the TensorFlow implementation:\n",
    "# https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/expert_utils.py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.log_soft = nn.LogSoftmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.log_soft(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SparseDispatcher(object):\n",
    "    \"\"\"Helper for implementing a mixture of experts.\n",
    "    The purpose of this class is to create input minibatches for the\n",
    "    experts and to combine the results of the experts to form a unified\n",
    "    output tensor.\n",
    "    There are two functions:\n",
    "    dispatch - take an input Tensor and create input Tensors for each expert.\n",
    "    combine - take output Tensors from each expert and form a combined output\n",
    "      Tensor.  Outputs from different experts for the same batch element are\n",
    "      summed together, weighted by the provided \"gates\".\n",
    "    The class is initialized with a \"gates\" Tensor, which specifies which\n",
    "    batch elements go to which experts, and the weights to use when combining\n",
    "    the outputs.  Batch element b is sent to expert e iff gates[b, e] != 0.\n",
    "    The inputs and outputs are all two-dimensional [batch, depth].\n",
    "    Caller is responsible for collapsing additional dimensions prior to\n",
    "    calling this class and reshaping the output to the original shape.\n",
    "    See common_layers.reshape_like().\n",
    "    Example use:\n",
    "    gates: a float32 `Tensor` with shape `[batch_size, num_experts]`\n",
    "    inputs: a float32 `Tensor` with shape `[batch_size, input_size]`\n",
    "    experts: a list of length `num_experts` containing sub-networks.\n",
    "    dispatcher = SparseDispatcher(num_experts, gates)\n",
    "    expert_inputs = dispatcher.dispatch(inputs)\n",
    "    expert_outputs = [experts[i](expert_inputs[i]) for i in range(num_experts)]\n",
    "    outputs = dispatcher.combine(expert_outputs)\n",
    "    The preceding code sets the output for a particular example b to:\n",
    "    output[b] = Sum_i(gates[b, i] * experts[i](inputs[b]))\n",
    "    This class takes advantage of sparsity in the gate matrix by including in the\n",
    "    `Tensor`s for expert i only the batch elements for which `gates[b, i] > 0`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_experts, gates):\n",
    "        \"\"\"Create a SparseDispatcher.\"\"\"\n",
    "\n",
    "        self._gates = gates\n",
    "        self._num_experts = num_experts\n",
    "        # sort experts\n",
    "        sorted_experts, index_sorted_experts = torch.nonzero(gates).sort(0)\n",
    "        # drop indices\n",
    "        _, self._expert_index = sorted_experts.split(1, dim=1)\n",
    "        # get according batch index for each expert\n",
    "        self._batch_index = sorted_experts[index_sorted_experts[:, 1], 0]\n",
    "        # calculate num samples that each expert gets\n",
    "        self._part_sizes = list((gates > 0).sum(0).numpy())\n",
    "        # expand gates to match with self._batch_index\n",
    "        gates_exp = gates[self._batch_index.flatten()]\n",
    "        self._nonzero_gates = torch.gather(gates_exp, 1, self._expert_index)\n",
    "\n",
    "    def dispatch(self, inp):\n",
    "        \"\"\"Create one input Tensor for each expert.\n",
    "        The `Tensor` for a expert `i` contains the slices of `inp` corresponding\n",
    "        to the batch elements `b` where `gates[b, i] > 0`.\n",
    "        Args:\n",
    "          inp: a `Tensor` of shape \"[batch_size, <extra_input_dims>]`\n",
    "        Returns:\n",
    "          a list of `num_experts` `Tensor`s with shapes\n",
    "            `[expert_batch_size_i, <extra_input_dims>]`.\n",
    "        \"\"\"\n",
    "\n",
    "        # assigns samples to experts whose gate is nonzero\n",
    "\n",
    "        # expand according to batch index so we can just split by _part_sizes\n",
    "        inp_exp = inp[self._batch_index].squeeze(1)\n",
    "        return torch.split(inp_exp, self._part_sizes, dim=0)\n",
    "\n",
    "    def combine(self, expert_out, multiply_by_gates=True):\n",
    "        \"\"\"Sum together the expert output, weighted by the gates.\n",
    "        The slice corresponding to a particular batch element `b` is computed\n",
    "        as the sum over all experts `i` of the expert output, weighted by the\n",
    "        corresponding gate values.  If `multiply_by_gates` is set to False, the\n",
    "        gate values are ignored.\n",
    "        Args:\n",
    "          expert_out: a list of `num_experts` `Tensor`s, each with shape\n",
    "            `[expert_batch_size_i, <extra_output_dims>]`.\n",
    "          multiply_by_gates: a boolean\n",
    "        Returns:\n",
    "          a `Tensor` with shape `[batch_size, <extra_output_dims>]`.\n",
    "        \"\"\"\n",
    "        # apply exp to expert outputs, so we are not longer in log space\n",
    "        print(len(expert_out), expert_out[1].size())\n",
    "        stitched = torch.cat(expert_out, 0).exp()\n",
    "        print(stitched.size())\n",
    "        if multiply_by_gates:\n",
    "            stitched = stitched.mul(self._nonzero_gates)\n",
    "            print(self._nonzero_gates)\n",
    "        zeros = torch.zeros(\n",
    "            self._gates.size(0), expert_out[-1].size(1), requires_grad=True\n",
    "        )\n",
    "        # combine samples that have been processed by the same k experts\n",
    "        combined = zeros.index_add(0, self._batch_index, stitched.float())\n",
    "        # add eps to all zero values in order to avoid nans when going back to log space\n",
    "        combined[combined == 0] = np.finfo(float).eps\n",
    "        # back to log space\n",
    "        return combined.log()\n",
    "\n",
    "    def expert_to_gates(self):\n",
    "        \"\"\"Gate values corresponding to the examples in the per-expert `Tensor`s.\n",
    "        Returns:\n",
    "          a list of `num_experts` one-dimensional `Tensor`s with type `tf.float32`\n",
    "              and shapes `[expert_batch_size_i]`\n",
    "        \"\"\"\n",
    "        # split nonzero gates for each expert\n",
    "        return torch.split(self._nonzero_gates, self._part_sizes, dim=0)\n",
    "\n",
    "\n",
    "class MoE(nn.Module):\n",
    "\n",
    "    \"\"\"Call a Sparsely gated mixture of experts layer with 1-layer Feed-Forward networks as experts.\n",
    "    Args:\n",
    "    input_size: integer - size of the input\n",
    "    output_size: integer - size of the input\n",
    "    num_experts: an integer - number of experts\n",
    "    hidden_size: an integer - hidden size of the experts\n",
    "    noisy_gating: a boolean\n",
    "    k: an integer - how many experts to use for each batch element\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, num_experts, noisy_gating=True, k=5):\n",
    "        super(MoE, self).__init__()\n",
    "        self.noisy_gating = noisy_gating\n",
    "        self.num_experts = num_experts\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.k = k\n",
    "        self.w_gate = nn.Parameter(\n",
    "            torch.zeros(input_size, num_experts), requires_grad=True\n",
    "        )\n",
    "        self.w_noise = nn.Parameter(\n",
    "            torch.zeros(input_size, num_experts), requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.normal = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "        assert self.k <= self.num_experts\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`.\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.Tensor([0])\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(\n",
    "        self, clean_values, noisy_values, noise_stddev, noisy_top_values\n",
    "    ):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "        threshold_positions_if_in = torch.arange(batch) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(\n",
    "            torch.gather(top_values_flat, 0, threshold_positions_if_in), 1\n",
    "        )\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(\n",
    "            torch.gather(top_values_flat, 0, threshold_positions_if_out), 1\n",
    "        )\n",
    "        # is each value currently in the top k.\n",
    "        prob_if_in = self.normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = self.normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "        See paper: https://arxiv.org/abs/1701.06538.\n",
    "        Args:\n",
    "          x: input Tensor with shape [batch_size, input_size]\n",
    "          train: a boolean - we only add noise at training time.\n",
    "          noise_epsilon: a float\n",
    "        Returns:\n",
    "          gates: a Tensor with shape [batch_size, num_experts]\n",
    "          load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.w_gate\n",
    "        if self.noisy_gating:\n",
    "            raw_noise_stddev = x @ self.w_noise\n",
    "            noise_stddev = (self.softplus(raw_noise_stddev) + noise_epsilon) * train\n",
    "            noisy_logits = clean_logits + (\n",
    "                torch.randn_like(clean_logits) * noise_stddev\n",
    "            )\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, : self.k]\n",
    "        top_k_indices = top_indices[:, : self.k]\n",
    "        top_k_gates = self.softmax(top_k_logits)\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "        if self.noisy_gating and self.k < self.num_experts:\n",
    "            load = (\n",
    "                self._prob_in_top_k(\n",
    "                    clean_logits, noisy_logits, noise_stddev, top_logits\n",
    "                )\n",
    "            ).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, query, key, train=True, loss_coef=1e-2):\n",
    "        \"\"\"Args:\n",
    "        x: tensor shape [batch_size, input_size]\n",
    "        train: a boolean scalar.\n",
    "        loss_coef: a scalar - multiplier on load-balancing losses\n",
    "        Returns:\n",
    "        y: a tensor with shape [batch_size, output_size].\n",
    "        extra_training_loss: a scalar.  This should be added into the overall\n",
    "        training loss of the model.  The backpropagation of this loss\n",
    "        encourages all experts to be approximately equally used across a batch.\n",
    "        \"\"\"\n",
    "        gates, load = self.noisy_top_k_gating(query, train)\n",
    "        # calculate importance loss\n",
    "        importance = gates.sum(0)\n",
    "        #\n",
    "        loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "        loss *= loss_coef\n",
    "\n",
    "        dispatcher = SparseDispatcher(self.num_experts, gates)\n",
    "        expert_inputs = dispatcher.dispatch(x)\n",
    "        gates = dispatcher.expert_to_gates()\n",
    "        y = dispatcher.combine(key)\n",
    "        return y, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_1 = torch.randn(100, 32)\n",
    "x_2 = torch.randn(100, 32)\n",
    "x_3 = torch.randn(100, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([x_1, x_2, x_3])\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the MoE layer\n",
    "moe = MoE(\n",
    "    input_size=768,\n",
    "    output_size=768,\n",
    "    num_experts=10,\n",
    "    k=5,\n",
    "    noisy_gating=True,\n",
    ")\n",
    "\n",
    "# forward\n",
    "# y_hat, aux_loss = moe(x_1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = torch.randn(20, 12, 768).unsqueeze(2)\n",
    "value = torch.randn(20, 12, 10, 768)\n",
    "gates, load = moe.noisy_top_k_gating(x_1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "gates.squeeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gorgeous-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AdapterFusionConfig, AdapterType, AutoModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "automatic-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "adapter_names = [f\"adapter_{i}\" for i in range(20)]\n",
    "for adapter_name in adapter_names:\n",
    "    base_model.add_adapter(adapter_name, adapter_type=AdapterType.text_task)\n",
    "fusion_config = AdapterFusionConfig.load(\"dynamic\", temperature=-5)\n",
    "base_model.set_active_adapters(adapter_names)\n",
    "base_model.add_fusion(adapter_names,fusion_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-competition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informative-possession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PfeifferConfig(original_ln_before=True, original_ln_after=True, residual_before_ln=True, adapter_residual_before_ln=False, ln_before=False, ln_after=False, mh_adapter=False, output_adapter=True, non_linearity='relu', reduction_factor=16, invertible_adapter=InvertibleAdapterConfig(block_type='nice', non_linearity='relu', reduction_factor=2), leave_out=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.config.adapters.get(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "written-duncan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-trained BERT tokenizer from Huggingface\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenize an input sentence\n",
    "sentence = \"It's also, clearly, great fun.\"\n",
    "\n",
    "# convert input tokens to indices and create PyTorch input tensor\n",
    "input_tensor = torch.tensor([tokenizer.encode(sentence) for i in range(20)])\n",
    "input_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.config.adapter_fusion[\"temperature\"]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "serious-boulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1207,  0.1630, -0.1404,  ..., -0.3977,  0.1520,  0.5696],\n",
       "          [ 0.4179, -0.0688, -0.2795,  ..., -0.3041,  0.3532,  0.3990],\n",
       "          [ 0.8635, -0.1008,  0.5260,  ..., -0.8003,  0.5659,  0.0475],\n",
       "          ...,\n",
       "          [ 0.6075,  0.2061,  0.5748,  ..., -0.2470, -0.2852, -0.3002],\n",
       "          [ 0.8881,  0.3087,  0.0201,  ...,  0.0293, -0.5853, -0.3446],\n",
       "          [ 0.1115,  0.4390,  0.0401,  ..., -0.1743,  0.3040, -0.0831]],\n",
       " \n",
       "         [[ 0.1363,  0.1695, -0.1281,  ..., -0.3921,  0.1543,  0.5669],\n",
       "          [ 0.3726, -0.0795, -0.2825,  ..., -0.2572,  0.3715,  0.3324],\n",
       "          [ 0.8525, -0.0550,  0.4882,  ..., -0.7421,  0.5554,  0.0065],\n",
       "          ...,\n",
       "          [ 0.6609,  0.1591,  0.5604,  ..., -0.2804, -0.1932, -0.2588],\n",
       "          [ 0.8860,  0.3071,  0.0184,  ...,  0.0306, -0.5896, -0.3420],\n",
       "          [ 0.1699,  0.4331,  0.0997,  ..., -0.1782,  0.3389, -0.0417]],\n",
       " \n",
       "         [[ 0.1029,  0.1710, -0.1524,  ..., -0.4141,  0.1474,  0.5850],\n",
       "          [ 0.4229, -0.0842, -0.3032,  ..., -0.2804,  0.3630,  0.3827],\n",
       "          [ 0.8296, -0.0556,  0.5441,  ..., -0.7176,  0.5509,  0.0392],\n",
       "          ...,\n",
       "          [ 0.6324,  0.1935,  0.5725,  ..., -0.2821, -0.2312, -0.3119],\n",
       "          [ 0.8997,  0.3000,  0.0261,  ...,  0.0348, -0.5689, -0.3351],\n",
       "          [ 0.1136,  0.4780,  0.0616,  ..., -0.1923,  0.3078, -0.0702]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1130,  0.1534, -0.1516,  ..., -0.3972,  0.1522,  0.5779],\n",
       "          [ 0.4171, -0.0855, -0.2791,  ..., -0.2764,  0.3664,  0.3673],\n",
       "          [ 0.9032, -0.0560,  0.5442,  ..., -0.7566,  0.5543,  0.0717],\n",
       "          ...,\n",
       "          [ 0.6648,  0.1978,  0.5404,  ..., -0.2468, -0.2719, -0.2990],\n",
       "          [ 0.8741,  0.3063,  0.0270,  ...,  0.0298, -0.5908, -0.3401],\n",
       "          [ 0.1250,  0.4453,  0.0491,  ..., -0.1645,  0.3144, -0.0484]],\n",
       " \n",
       "         [[ 0.1064,  0.1495, -0.1423,  ..., -0.3890,  0.1381,  0.5831],\n",
       "          [ 0.4113, -0.1145, -0.2826,  ..., -0.2752,  0.3559,  0.3432],\n",
       "          [ 0.8667, -0.0288,  0.5026,  ..., -0.7402,  0.5807,  0.0258],\n",
       "          ...,\n",
       "          [ 0.6291,  0.1545,  0.5362,  ..., -0.2640, -0.2738, -0.3066],\n",
       "          [ 0.8854,  0.3119,  0.0233,  ...,  0.0362, -0.5893, -0.3473],\n",
       "          [ 0.1050,  0.4493,  0.0492,  ..., -0.2015,  0.2901, -0.0586]],\n",
       " \n",
       "         [[ 0.1251,  0.1674, -0.1483,  ..., -0.3944,  0.1293,  0.5773],\n",
       "          [ 0.4164, -0.0840, -0.3255,  ..., -0.2794,  0.3886,  0.3862],\n",
       "          [ 0.8471, -0.0869,  0.5510,  ..., -0.7280,  0.5965,  0.0536],\n",
       "          ...,\n",
       "          [ 0.6420,  0.2264,  0.5117,  ..., -0.2873, -0.2693, -0.3375],\n",
       "          [ 0.8766,  0.3142,  0.0165,  ...,  0.0305, -0.5806, -0.3339],\n",
       "          [ 0.1421,  0.4411,  0.0296,  ..., -0.1937,  0.2972, -0.0540]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[-0.8001, -0.2935, -0.7862,  ..., -0.7505, -0.5493,  0.8583],\n",
       "         [-0.7932, -0.2921, -0.7670,  ..., -0.7310, -0.5404,  0.8620],\n",
       "         [-0.7915, -0.2927, -0.7938,  ..., -0.7652, -0.5361,  0.8611],\n",
       "         ...,\n",
       "         [-0.7914, -0.2809, -0.7789,  ..., -0.7459, -0.5409,  0.8578],\n",
       "         [-0.7977, -0.2992, -0.7923,  ..., -0.7633, -0.5419,  0.8644],\n",
       "         [-0.7997, -0.2966, -0.7848,  ..., -0.7566, -0.5525,  0.8629]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imperial-progress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 12, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].unsqueeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].transpose(-2, -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.squeeze(torch.matmul(outputs[0][:1], outputs[0].transpose(-2, -1)), dim=2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].size(),outputs[0][:1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].transpose(-2, -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "infinite-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "divine-coverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5480, 0.5647, 0.4442,  ..., 0.3454, 0.5604, 0.7155],\n",
       "         [0.6620, 0.4726, 0.3899,  ..., 0.3805, 0.6380, 0.6551],\n",
       "         [0.8061, 0.4599, 0.7005,  ..., 0.2118, 0.7143, 0.5190],\n",
       "         ...,\n",
       "         [0.7282, 0.5816, 0.7173,  ..., 0.4025, 0.3877, 0.3820],\n",
       "         [0.8127, 0.6212, 0.5080,  ..., 0.5117, 0.2792, 0.3652],\n",
       "         [0.5444, 0.6697, 0.5160,  ..., 0.4308, 0.6194, 0.4669]],\n",
       "\n",
       "        [[0.5542, 0.5673, 0.4490,  ..., 0.3475, 0.5613, 0.7146],\n",
       "         [0.6453, 0.4683, 0.3888,  ..., 0.3985, 0.6449, 0.6302],\n",
       "         [0.8030, 0.4781, 0.6873,  ..., 0.2290, 0.7107, 0.5026],\n",
       "         ...,\n",
       "         [0.7457, 0.5632, 0.7124,  ..., 0.3896, 0.4234, 0.3979],\n",
       "         [0.8122, 0.6206, 0.5074,  ..., 0.5122, 0.2777, 0.3662],\n",
       "         [0.5675, 0.6675, 0.5397,  ..., 0.4293, 0.6326, 0.4834]],\n",
       "\n",
       "        [[0.5410, 0.5679, 0.4394,  ..., 0.3394, 0.5586, 0.7207],\n",
       "         [0.6638, 0.4665, 0.3809,  ..., 0.3896, 0.6417, 0.6490],\n",
       "         [0.7966, 0.4778, 0.7068,  ..., 0.2365, 0.7091, 0.5156],\n",
       "         ...,\n",
       "         [0.7365, 0.5767, 0.7165,  ..., 0.3890, 0.4086, 0.3775],\n",
       "         [0.8159, 0.6179, 0.5104,  ..., 0.5139, 0.2847, 0.3688],\n",
       "         [0.5452, 0.6837, 0.5246,  ..., 0.4238, 0.6209, 0.4720]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5450, 0.5610, 0.4398,  ..., 0.3456, 0.5605, 0.7183],\n",
       "         [0.6617, 0.4659, 0.3901,  ..., 0.3911, 0.6430, 0.6433],\n",
       "         [0.8168, 0.4777, 0.7069,  ..., 0.2246, 0.7103, 0.5286],\n",
       "         ...,\n",
       "         [0.7469, 0.5784, 0.7055,  ..., 0.4025, 0.3929, 0.3825],\n",
       "         [0.8090, 0.6203, 0.5108,  ..., 0.5119, 0.2773, 0.3669],\n",
       "         [0.5497, 0.6720, 0.5196,  ..., 0.4347, 0.6234, 0.4807]],\n",
       "\n",
       "        [[0.5424, 0.5594, 0.4434,  ..., 0.3487, 0.5549, 0.7201],\n",
       "         [0.6596, 0.4544, 0.3887,  ..., 0.3916, 0.6390, 0.6343],\n",
       "         [0.8070, 0.4885, 0.6924,  ..., 0.2296, 0.7193, 0.5103],\n",
       "         ...,\n",
       "         [0.7354, 0.5614, 0.7041,  ..., 0.3959, 0.3921, 0.3796],\n",
       "         [0.8120, 0.6224, 0.5093,  ..., 0.5145, 0.2778, 0.3642],\n",
       "         [0.5418, 0.6734, 0.5196,  ..., 0.4202, 0.6141, 0.4766]],\n",
       "\n",
       "        [[0.5498, 0.5665, 0.4411,  ..., 0.3466, 0.5515, 0.7181],\n",
       "         [0.6614, 0.4665, 0.3724,  ..., 0.3900, 0.6512, 0.6503],\n",
       "         [0.8015, 0.4654, 0.7092,  ..., 0.2333, 0.7246, 0.5214],\n",
       "         ...,\n",
       "         [0.7396, 0.5896, 0.6956,  ..., 0.3870, 0.3938, 0.3679],\n",
       "         [0.8096, 0.6233, 0.5066,  ..., 0.5122, 0.2807, 0.3692],\n",
       "         [0.5565, 0.6704, 0.5118,  ..., 0.4232, 0.6169, 0.4785]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.distributions.normal import Normal\n",
    "\n",
    "Normal(torch.tensor([0.0]).to(\"cuda\"), torch.tensor([1.0]).to(\"cuda\")).cdf(a)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attractive-finnish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1207,  0.1630, -0.1404,  ..., -0.3977,  0.1520,  0.5696],\n",
       "         [ 0.4179, -0.0688, -0.2795,  ..., -0.3041,  0.3532,  0.3990],\n",
       "         [ 0.8635, -0.1008,  0.5260,  ..., -0.8003,  0.5659,  0.0475],\n",
       "         ...,\n",
       "         [ 0.6075,  0.2061,  0.5748,  ..., -0.2470, -0.2852, -0.3002],\n",
       "         [ 0.8881,  0.3087,  0.0201,  ...,  0.0293, -0.5853, -0.3446],\n",
       "         [ 0.1115,  0.4390,  0.0401,  ..., -0.1743,  0.3040, -0.0831]],\n",
       "\n",
       "        [[ 0.1363,  0.1695, -0.1281,  ..., -0.3921,  0.1543,  0.5669],\n",
       "         [ 0.3726, -0.0795, -0.2825,  ..., -0.2572,  0.3715,  0.3324],\n",
       "         [ 0.8525, -0.0550,  0.4882,  ..., -0.7421,  0.5554,  0.0065],\n",
       "         ...,\n",
       "         [ 0.6609,  0.1591,  0.5604,  ..., -0.2804, -0.1932, -0.2588],\n",
       "         [ 0.8860,  0.3071,  0.0184,  ...,  0.0306, -0.5896, -0.3420],\n",
       "         [ 0.1699,  0.4331,  0.0997,  ..., -0.1782,  0.3389, -0.0417]],\n",
       "\n",
       "        [[ 0.1029,  0.1710, -0.1524,  ..., -0.4141,  0.1474,  0.5850],\n",
       "         [ 0.4229, -0.0842, -0.3032,  ..., -0.2804,  0.3630,  0.3827],\n",
       "         [ 0.8296, -0.0556,  0.5441,  ..., -0.7176,  0.5509,  0.0392],\n",
       "         ...,\n",
       "         [ 0.6324,  0.1935,  0.5725,  ..., -0.2821, -0.2312, -0.3119],\n",
       "         [ 0.8997,  0.3000,  0.0261,  ...,  0.0348, -0.5689, -0.3351],\n",
       "         [ 0.1136,  0.4780,  0.0616,  ..., -0.1923,  0.3078, -0.0702]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1130,  0.1534, -0.1516,  ..., -0.3972,  0.1522,  0.5779],\n",
       "         [ 0.4171, -0.0855, -0.2791,  ..., -0.2764,  0.3664,  0.3673],\n",
       "         [ 0.9032, -0.0560,  0.5442,  ..., -0.7566,  0.5543,  0.0717],\n",
       "         ...,\n",
       "         [ 0.6648,  0.1978,  0.5404,  ..., -0.2468, -0.2719, -0.2990],\n",
       "         [ 0.8741,  0.3063,  0.0270,  ...,  0.0298, -0.5908, -0.3401],\n",
       "         [ 0.1250,  0.4453,  0.0491,  ..., -0.1645,  0.3144, -0.0484]],\n",
       "\n",
       "        [[ 0.1064,  0.1495, -0.1423,  ..., -0.3890,  0.1381,  0.5831],\n",
       "         [ 0.4113, -0.1145, -0.2826,  ..., -0.2752,  0.3559,  0.3432],\n",
       "         [ 0.8667, -0.0288,  0.5026,  ..., -0.7402,  0.5807,  0.0258],\n",
       "         ...,\n",
       "         [ 0.6291,  0.1545,  0.5362,  ..., -0.2640, -0.2738, -0.3066],\n",
       "         [ 0.8854,  0.3119,  0.0233,  ...,  0.0362, -0.5893, -0.3473],\n",
       "         [ 0.1050,  0.4493,  0.0492,  ..., -0.2015,  0.2901, -0.0586]],\n",
       "\n",
       "        [[ 0.1251,  0.1674, -0.1483,  ..., -0.3944,  0.1293,  0.5773],\n",
       "         [ 0.4164, -0.0840, -0.3255,  ..., -0.2794,  0.3886,  0.3862],\n",
       "         [ 0.8471, -0.0869,  0.5510,  ..., -0.7280,  0.5965,  0.0536],\n",
       "         ...,\n",
       "         [ 0.6420,  0.2264,  0.5117,  ..., -0.2873, -0.2693, -0.3375],\n",
       "         [ 0.8766,  0.3142,  0.0165,  ...,  0.0305, -0.5806, -0.3339],\n",
       "         [ 0.1421,  0.4411,  0.0296,  ..., -0.1937,  0.2972, -0.0540]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-sharp",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge",
   "language": "python",
   "name": "knowledge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
